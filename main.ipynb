{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "11d5baa8-4272-4ca4-bc34-bea4ddb6996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from model import GPTConfig, GPT\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4593b-f3d7-492b-a0bc-27c0df4b8fda",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7053fed2-7caa-42a7-ae4a-18768369175b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the unique characters: <BOS> | <EOS> | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | 41 | 42 | 43 | 44 | 45 | 46 | 47 | 48 | 49 | 50 | 51 | 52 | 53 | 54 | 55 | 56 | 57 | 58 | 59 | 60 | 61 | 62 | 63 | 64 | 65 | 66 | 67 | 68 | 69 | 70 | 71 | 72 | 73 | 74 | 75 | 76 | 77 | 78 | 79 | 80 | 81 | 82 | 83 | 84 | 85 | 86 | 87 | 88 | 89 | 90 | 91 | 92 | 93 | 94 | 95 | 96 | 97 | 98 | 99 | 100 | 101 | 102 | 103 | 104 | 105 | 106 | 107 | 108 | 109 | 110 | 111 | 112 | 113 | 114 | 115 | 116 | 117 | 118 | 119 | 120 | 121 | 122 | 123 | 124 | 125 | 126 | 127 | 128 | 129 | 130 | 131 | 132 | 133 | 134 | 135 | 136 | 137 | 138 | 139 | 140 | 141 | 142 | 143 | 144 | 145 | 146 | 147 | 148 | 149 | 150 | 151 | 152 | 153 | 154 | 155 | 156 | 157 | 158 | 159 | 160 | 161 | 162 | 163 | 164 | 165 | 166 | 167 | 168 | 169 | 170 | 171 | 172 | 173 | 174 | 175 | 176 | 177 | 178 | 179 | 180 | 181 | 182 | 183 | 184 | 185 | 186 | 187 | 188 | 189 | 190 | 191 | 192 | 193 | 194 | 195 | 196 | 197 | 198 | 199 | 200 | 201 | 202 | 203 | 204 | 205 | 206 | 207 | 208 | 209 | 210 | 211 | 212 | 213 | 214 | 215 | 216 | 217 | 218 | 219 | 220 | 221 | 222 | 223 | 224 | 225 | 226 | 227 | 228 | 229 | 230 | 231 | 232 | 233 | 234 | 235 | 236 | 237 | 238 | 239 | 240 | 241 | 242 | 243 | 244 | 245 | 246 | 247 | 248 | 249 | 250 | 251 | 252 | 253 | 254 | 255 | 256 | 257 | 258 | 259 | 260 | 261 | 262 | 263 | 264 | 265 | 266 | 267 | 268 | 269 | 270 | 271 | 272 | 273 | 274 | 275 | 276 | 277 | 278 | 279 | 280 | 281 | 282 | 283 | 284 | 285 | 286 | 287 | 288 | 289 | 290 | 291 | 292 | 293 | 294 | 295 | 296 | 297 | 298 | 299 | 300 | 301 | 302 | 303 | 304 | 305 | 306 | 307 | 308 | 309 | 310 | 311 | 312 | 313 | 314 | 315 | 316 | 317 | 318 | 319 | 320 | 321 | 322 | 323 | 324 | 325 | 326 | 327 | 328 | 329 | 330 | 331 | 332 | 333 | 334 | 335 | 336 | 337 | 338 | 339 | 340 | 341 | 342 | 343 | 344 | 345 | 346 | 347 | 348 | 349 | 350 | 351 | 352 | 353 | 354 | 355 | 356 | 357 | 358 | 359 | 360 | 361 | 362 | 363 | 364 | 365 | 366 | 367 | 368 | 369 | 370 | 371 | 372 | 373 | 374 | 375 | 376 | 377 | 378 | 379 | 380 | 381 | 382 | 383 | 384 | 385 | 386 | 387 | 388 | 389 | 390 | 391 | 392 | 393 | 394 | 395 | 396 | 397 | 398 | 399 | 400 | 401 | 402 | 403 | 404 | 405 | 406 | 407 | 408 | 409 | 410 | 411 | 412 | 413 | 414 | 415 | 416 | 417 | 418 | 419 | 420 | 421 | 422 | 423 | 424 | 425 | 426 | 427 | 428 | 429 | 430 | 431 | 432 | 433 | 434 | 435 | 436 | 437 | 438 | 439 | 440 | 441 | 442 | 443 | 444 | 445 | 446 | 447 | 448 | 449 | 450 | 451 | 452 | 453 | 454 | 455 | 456 | 457 | 458 | 459 | 460 | 461 | 462 | 463 | 464 | 465 | 466 | 467 | 468 | 469 | 470 | 471 | 472 | 473 | 474 | 475 | 476 | 477 | 478 | 479 | 480 | 481 | 482 | 483 | 484 | 485 | 486 | 487 | 488 | 489 | 490 | 491 | 492 | 493 | 494 | 495 | 496 | 497 | 498 | 499 | 500 | 501 | 502 | 503 | 504 | 505 | 506 | 507 | 508 | 509 | 510 | 511 | 512 | 513 | 514 | 515 | 516 | 517 | 518 | 519 | 520 | 521 | 522 | 523 | 524 | 525 | 526 | 527 | 528 | 529 | 530 | 531 | 532 | 533 | 534 | 535 | 536 | 537 | 538 | 539 | 540 | 541 | 542 | 543 | 544 | 545 | 546 | 547 | 548 | 549 | 550 | -1 | -2 | -3 | -4 | -5 | -6 | -7 | -8 | -9 | -10 | -11 | -12 | -13 | -14 | -15 | -16 | -17 | -18 | -19 | -20 | -21 | -22 | -23 | -24 | -25 | -26 | -27 | -28 | -29 | -30 | -31 | -32 | -33 | -34 | -35 | -36 | -37 | -38 | -39 | -40 | -41 | -42 | -43 | -44 | -45 | -46 | -47 | -48 | -49 | -50 | -51 | -52 | -53 | -54 | -55 | -56 | -57 | -58 | -59 | -60 | -61 | -62 | -63 | -64 | -65 | -66 | -67 | -68 | -69 | -70 | -71 | -72 | -73 | -74 | -75 | -76 | -77 | -78 | -79 | -80 | -81 | -82 | -83 | -84 | -85 | -86 | -87 | -88 | -89 | -90 | -91 | -92 | -93 | -94 | -95 | -96 | -97 | -98 | -99 | -100 | -101 | -102 | -103 | -104 | -105 | -106 | -107 | -108 | -109 | -110 | -111 | -112 | -113 | -114 | -115 | -116 | -117 | -118 | -119 | -120 | -121 | -122 | -123 | -124 | -125 | -126 | -127 | -128 | -129 | -130 | -131 | -132 | -133 | -134 | -135 | -136 | -137 | -138 | -139 | -140 | -141 | -142 | -143 | -144 | -145 | -146 | -147 | -148 | -149 | -150 | -151 | -152 | -153 | -154 | -155 | -156 | -157 | -158 | -159 | -160 | -161 | -162 | -163 | -164 | -165 | -166 | -167 | -168 | -169 | -170 | -171 | -172 | -173 | -174 | -175 | -176 | -177 | -178 | -179 | -180 | -181 | -182 | -183 | -184 | -185 | -186 | -187 | -188 | -189 | -190 | -191 | -192 | -193 | -194 | -195 | -196 | -197 | -198 | -199 | -200 | -201 | -202 | -203 | -204 | -205 | -206 | -207 | -208 | -209 | -210 | -211 | -212 | -213 | -214 | -215 | -216 | -217 | -218 | -219 | -220 | -221 | -222 | -223 | -224 | -225 | -226 | -227 | -228 | -229 | -230 | -231 | -232 | -233 | -234 | -235 | -236 | -237 | -238 | -239 | -240 | -241 | -242 | -243 | -244 | -245 | -246 | -247 | -248 | -249 | -250 | -251 | -252 | -253 | -254 | -255 | -256 | -257 | -258 | -259 | -260 | -261 | -262 | -263 | -264 | -265 | -266 | -267 | -268 | -269 | -270 | -271 | -272 | -273 | -274 | -275 | -276 | -277 | -278 | -279 | -280 | -281 | -282 | -283 | -284 | -285 | -286 | -287 | -288 | -289 | -290 | -291 | -292 | -293 | -294 | -295 | -296 | -297 | -298 | -299 | -300 | -301 | -302 | -303 | -304 | -305 | -306 | -307 | -308 | -309 | -310 | -311 | -312 | -313 | -314 | -315 | -316 | -317 | -318 | -319 | -320 | -321 | -322 | -323 | -324 | -325 | -326 | -327 | -328 | -329 | -330 | -331 | -332 | -333 | -334 | -335 | -336 | -337 | -338 | -339 | -340 | -341 | -342 | -343 | -344 | -345 | -346 | -347 | -348 | -349 | -350 | -351 | -352 | -353 | -354 | -355 | -356 | -357 | -358 | -359 | -360 | -361 | -362 | -363 | -364 | -365 | -366 | -367 | -368 | -369 | -370 | -371 | -372 | -373 | -374 | -375 | -376 | -377 | -378 | -379 | -380 | -381 | -382 | -383 | -384 | -385 | -386 | -387 | -388 | -389 | -390 | -391 | -392 | -393 | -394 | -395 | -396 | -397 | -398 | -399 | -400 | -401 | -402 | -403 | -404 | -405 | -406 | -407 | -408 | -409 | -410 | -411 | -412 | -413 | -414 | -415 | -416 | -417 | -418 | -419 | -420 | -421 | -422 | -423 | -424 | -425 | -426 | -427 | -428 | -429 | -430 | -431 | -432 | -433 | -434 | -435 | -436 | -437 | -438 | -439 | -440 | -441 | -442 | -443 | -444 | -445 | -446 | -447 | -448 | -449 | -450 | -451 | -452 | -453 | -454 | -455 | -456 | -457 | -458 | -459 | -460 | -461 | -462 | -463 | -464 | -465 | -466 | -467 | -468 | -469 | -470 | -471 | -472 | -473 | -474 | -475 | -476 | -477 | -478 | -479 | -480 | -481 | -482 | -483 | -484 | -485 | -486 | -487 | -488 | -489 | -490 | -491 | -492 | -493 | -494 | -495 | -496 | -497 | -498 | -499 | -500 | -501 | -502 | -503 | -504 | -505 | -506 | -507 | -508 | -509 | -510 | -511 | -512 | -513 | -514 | -515 | -516 | -517 | -518 | -519 | -520 | -521 | -522 | -523 | -524 | -525 | -526 | -527 | -528 | -529 | -530 | -531 | -532 | -533 | -534 | -535 | -536 | -537 | -538 | -539 | -540 | -541 | -542 | -543 | -544 | -545 | -546 | -547 | -548 | -549 | -550\n",
      "vocab size: 1,103\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "chars = ['<BOS>', '<EOS>'] + [str(i) for i in range(0, 551)] + [str(-i) for i in range(1, 551)]\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", ' | '.join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")\n",
    "# make a vocab file\n",
    "# with open('./data/arithmetic/vocab_arithmetic.txt', 'w', encoding='utf-8') as fp:\n",
    "#     fp.write('\\n'.join(arithmetic_text))\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "def encode(seq):\n",
    "    length = len(seq)\n",
    "    return [stoi['<BOS>']] + [stoi[str(c)] for c in seq] + [stoi['<EOS>']] # encoder: take a string, output a list of integers\n",
    "\n",
    "def decode(l):\n",
    "    return [int(itos[i]) for i in l[1:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c62d5-f37a-4697-adbf-228c19b962a3",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "91f40093-7791-4692-8bab-566f67fa0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR(1)\n",
    "def sequence_generator(starting=0, length=40, persistence=0.5, noise_scale=100) -> list:\n",
    "    seq = [starting]\n",
    "    for i in range(length-1):\n",
    "        noise = np.random.normal(0, noise_scale)\n",
    "        next_element = persistence * seq[-1] + noise\n",
    "        seq.append(int(next_element))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "116ded41-5917-4818-b03b-a1913cc9e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 100000/100000 [00:02<00:00, 36418.12it/s]\n"
     ]
    }
   ],
   "source": [
    "my_generator = np.random.default_rng()\n",
    "synthetic_data = []\n",
    "for _ in tqdm(range(100000)):\n",
    "    persistence = my_generator.beta(0.27, 0.27)\n",
    "    starting = my_generator.integers(-5, 5)\n",
    "    seq = sequence_generator(starting=0, length=43, persistence=persistence, noise_scale=20)\n",
    "    synthetic_data.append(seq)\n",
    "\n",
    "# np.save('synthetic_data/length43_beta027.npy', synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cffad1ec-acfc-448c-b8c5-051cca5bbdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_token = []\n",
    "for seq in synthetic_data:\n",
    "    synthetic_token.append(encode(seq))\n",
    "\n",
    "train_token = synthetic_token[:int(len(synthetic_token)*0.9)]\n",
    "valid_token = synthetic_token[int(len(synthetic_token)*0.9):]\n",
    "\n",
    "# export to bin files\n",
    "train_ids = np.array(train_token, dtype=np.int32)\n",
    "val_ids = np.array(valid_token, dtype=np.int32)\n",
    "np.save('./synthetic_data/train_length43_beta027.npy', train_ids)\n",
    "np.save('./synthetic_data/val_length43_beta027.npy', val_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f51004-9233-45e2-84c0-939a86de7fac",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1cfbb3c2-8cfb-48e4-a1f0-378f02494df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size is (90000, 45) \n",
      "valset size is (10000, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2048, 44]), torch.Size([2048, 44]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data in\n",
    "train_ids = np.load(\"./synthetic_data/train_length43_beta027.npy\")\n",
    "val_ids = np.load(\"./synthetic_data/val_length43_beta027.npy\")\n",
    "print(\"trainset size is\", train_ids.shape, \"\\nvalset size is\", val_ids.shape)\n",
    "\n",
    "def get_batch(dataset, batch_size=64):\n",
    "    max_n = len(dataset)\n",
    "    idx = np.random.randint(max_n, size=batch_size)\n",
    "    \n",
    "    x = torch.tensor(dataset[idx, :-1])\n",
    "    y = torch.tensor(dataset[idx, 1:])  # x and y are overlapped, offset by 1\n",
    "    return x, y\n",
    "\n",
    "test_batch_x, test_batch_y = get_batch(train_ids, batch_size=2048)\n",
    "test_batch_x.shape, test_batch_y.shape  # block size or context size is 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "74e43001-942c-4db0-a574-4f4358162326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 6.58M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(1103, 256)\n",
       "    (wpe): Embedding(44, 256)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=1103, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = dict(n_layer=8, n_head=8, n_embd=256, block_size=val_ids.shape[1]-1,\n",
    "                  bias=False, vocab_size=vocab_size, dropout=0.2)\n",
    "config = GPTConfig(**model_args)\n",
    "model = GPT(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63943dc6-bc74-4c02-92fd-e62a05310405",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "model.train()\n",
    "\n",
    "# val_batch_x, val_batch_y = get_batch(val_ids, batch_size=512)\n",
    "# val_batch_x, val_batch_y = val_batch_x.to(device), val_batch_y.type(torch.LongTensor).to(device)\n",
    "\n",
    "p_bar = tqdm(range(2000))\n",
    "for ite in p_bar:\n",
    "    train_batch_x, train_batch_y = get_batch(train_ids, batch_size=2048)\n",
    "    train_batch_x, train_batch_y = train_batch_x.to(device), train_batch_y.type(torch.LongTensor).to(device)\n",
    "    logit, loss, _ = model(train_batch_x, train_batch_y)\n",
    "    # _, val_loss, _ = model(val_batch_x, val_batch_y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # if (ite+1)%100==0:\n",
    "    #     val_batch_x, val_batch_y = get_batch(val_ids, batch_size=2048)\n",
    "    #     val_batch_x, val_batch_y = val_batch_x.to(device), val_batch_y.type(torch.LongTensor).to(device)\n",
    "    #     _, val_loss, _ = model(val_batch_x, val_batch_y)\n",
    "    #     # val_loss_all.append(val_loss.detach().cpu().numpy())\n",
    "    #     del val_batch_x, val_batch_y, val_loss\n",
    "    #     torch.cuda.empty_cache()\n",
    "\n",
    "    p_bar.set_postfix({'val_loss': loss.detach().cpu().numpy()})\n",
    "\n",
    "    if (ite+1)%100==0:\n",
    "        torch.save(model, f'saved_model/len42_beta027/sequence-GPT-{ite}.pt')\n",
    "    \n",
    "# torch.save(model, 'saved_model/arithmetic-GPT-eco-uni.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97245b-3af1-4ff9-a5c0-79b3cdfaa975",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316193b-591c-4d49-9e96-8a1d933ae233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('saved_model/exponential_beta_22/arithmetic-GPT-1999.pt').to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab64dd8-3f2c-4722-b3b4-e4abf71ca1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
